"""
AI åˆ†æç»“æœæ•°æ®åº“æ“ä½œæ¨¡å—
ä¿å­˜å’Œæ‰¹é‡å¤„ç†æ¨æ–‡åˆ†æç»“æœ
"""

from typing import Dict, Any

from .client import OllamaClient
from .analyzer import TweetAnalyzer


async def save_analysis_to_db(tweet_id: int, analysis: Dict[str, Any]) -> bool:
    """
    å°† AI åˆ†æç»“æœä¿å­˜åˆ°æ•°æ®åº“

    Args:
        tweet_id: æ¨æ–‡ ID
        analysis: full_analysis è¿”å›çš„åˆ†æç»“æœ

    Returns:
        bool: ä¿å­˜æˆåŠŸè¿”å› True
    """
    try:
        from app.core.supabase import get_supabase_service

        supabase = get_supabase_service()

        # æå–è‚¡å¸‚ç›¸å…³æ€§æ•°æ®
        stock_related_data = analysis.get("is_stock_related", {})

        # æ„å»ºæ›´æ–°æ•°æ®
        update_data = {
            # æƒ…æ„Ÿåˆ†æ
            "ai_sentiment": analysis.get("sentiment", {}).get("sentiment"),
            "ai_sentiment_confidence": analysis.get("sentiment", {}).get("confidence"),
            "ai_sentiment_reasoning": analysis.get("sentiment", {}).get("reasoning"),
            # è‚¡ç¥¨ä»£ç å’Œæ ‡ç­¾ (JSONB)
            "ai_tickers": analysis.get("tickers", []),
            "ai_tags": analysis.get("tags", []),
            # æŠ•èµ„ä¿¡å· (JSONB)
            "ai_trading_signal": analysis.get("trading_signal"),
            # æ‘˜è¦
            "ai_summary": analysis.get("summary"),
            # è‚¡å¸‚ç›¸å…³æ€§
            "ai_is_stock_related": stock_related_data.get("is_stock_related", False),
            "ai_stock_related_confidence": stock_related_data.get("confidence"),
            "ai_stock_related_reason": stock_related_data.get("reason"),
            # å…ƒæ•°æ®
            "ai_analyzed_at": analysis.get("analyzed_at"),
            "ai_model": analysis.get("model"),
        }

        # æ›´æ–°æ•°æ®åº“
        supabase.table("kol_tweets").update(update_data).eq("id", tweet_id).execute()

        return True

    except Exception as e:
        print(f"âŒ ä¿å­˜ AI åˆ†æç»“æœå¤±è´¥ (tweet_id={tweet_id}): {e}")
        return False


async def analyze_and_save_tweet(tweet_id: int, tweet_text: str) -> Dict[str, Any]:
    """
    åˆ†ææ¨æ–‡å¹¶ä¿å­˜åˆ°æ•°æ®åº“

    Args:
        tweet_id: æ¨æ–‡ ID
        tweet_text: æ¨æ–‡æ–‡æœ¬

    Returns:
        Dict: åˆ†æç»“æœ
    """
    async with OllamaClient() as client:
        analyzer = TweetAnalyzer(client)
        analysis = await analyzer.full_analysis(tweet_text)

        # ä¿å­˜åˆ°æ•°æ®åº“
        await save_analysis_to_db(tweet_id, analysis)

        return analysis


async def batch_analyze_tweets(limit: int = 10) -> Dict[str, Any]:
    """
    æ‰¹é‡åˆ†ææœªå¤„ç†çš„æ¨æ–‡

    Args:
        limit: æ¯æ‰¹å¤„ç†çš„æ¨æ–‡æ•°é‡

    Returns:
        Dict: å¤„ç†ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        from app.core.supabase import get_supabase_service

        supabase = get_supabase_service()

        # æŸ¥è¯¢æœªåˆ†æçš„æ¨æ–‡
        result = (
            supabase.table("kol_tweets")
            .select("id, tweet_text")
            .is_("ai_analyzed_at", "null")
            .order("created_at", desc=True)
            .limit(limit)
            .execute()
        )

        tweets = result.data
        if not tweets:
            return {
                "processed": 0,
                "success": 0,
                "failed": 0,
                "message": "æ²¡æœ‰å¾…åˆ†æçš„æ¨æ–‡",
            }

        stats = {"processed": 0, "success": 0, "failed": 0, "results": []}

        async with OllamaClient() as client:
            analyzer = TweetAnalyzer(client)

            for tweet in tweets:
                tweet_id = tweet["id"]
                tweet_text = tweet["tweet_text"]

                try:
                    print(f"ğŸ” åˆ†ææ¨æ–‡ #{tweet_id}: {tweet_text[:50]}...")

                    analysis = await analyzer.full_analysis(tweet_text)
                    saved = await save_analysis_to_db(tweet_id, analysis)

                    stats["processed"] += 1
                    if saved:
                        stats["success"] += 1
                        stats["results"].append(
                            {
                                "tweet_id": tweet_id,
                                "sentiment": analysis.get("sentiment", {}).get(
                                    "sentiment"
                                ),
                                "tickers": analysis.get("tickers", []),
                                "success": True,
                            }
                        )
                        print(
                            f"   âœ… æƒ…æ„Ÿ: {analysis.get('sentiment', {}).get('sentiment')} | "
                            f"è‚¡ç¥¨: {analysis.get('tickers', [])}"
                        )
                    else:
                        stats["failed"] += 1
                        stats["results"].append(
                            {
                                "tweet_id": tweet_id,
                                "success": False,
                                "error": "ä¿å­˜å¤±è´¥",
                            }
                        )

                except Exception as e:
                    stats["processed"] += 1
                    stats["failed"] += 1
                    stats["results"].append(
                        {"tweet_id": tweet_id, "success": False, "error": str(e)}
                    )
                    print(f"   âŒ åˆ†æå¤±è´¥: {e}")

        return stats

    except Exception as e:
        return {"processed": 0, "success": 0, "failed": 0, "error": str(e)}
