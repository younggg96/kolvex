"""
æ ¸å¿ƒçˆ¬è™«ç±» - BatchKOLScraper
"""

import random
import time
from typing import List, Dict, Set, Tuple, Optional

# Playwright ç›¸å…³å¯¼å…¥
try:
    from playwright.sync_api import sync_playwright, Page

    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False
    Page = None

from .config import (
    COOKIES_FILE,
    USER_AGENTS,
    DEFAULT_MAX_POSTS_PER_USER,
    DEFAULT_DELAY_BETWEEN_USERS,
    DEFAULT_DELAY_DURING_SCROLL,
    DEFAULT_MAX_SCROLLS,
    PAGE_LOAD_TIMEOUT,
    ELEMENT_WAIT_TIMEOUT,
    NETWORK_IDLE_TIMEOUT,
    SETUP_LOGIN_TIMEOUT,
    BROWSER_ARGS,
    BROWSER_VIEWPORT,
    BROWSER_LOCALE,
    BROWSER_TIMEZONE,
)
from .database import (
    get_supabase_client,
    insert_tweet,
    upsert_kol_profile,
    get_stats,
)
from .utils import random_sleep, load_cookies, save_cookies
from .extractors import extract_user_profile, extract_tweet_text, extract_tweet_metadata


class BatchKOLScraper:
    """
    æ‰¹é‡ KOL çˆ¬è™«ç±»

    æ”¯æŒä¸¤ç§æ¨¡å¼:
    1. Setup Mode: headless=Falseï¼Œç”¨äºæ‰‹åŠ¨ç™»å½•å¹¶ä¿å­˜ cookies
    2. Batch Mode: åˆ©ç”¨å·²ä¿å­˜çš„ cookies è¿›è¡Œæ‰¹é‡çˆ¬å–
    """

    def __init__(
        self,
        cookies_file: str = None,
        headless: bool = False,
        max_posts_per_user: int = DEFAULT_MAX_POSTS_PER_USER,
        delay_between_users: Tuple[float, float] = DEFAULT_DELAY_BETWEEN_USERS,
        delay_during_scroll: Tuple[float, float] = DEFAULT_DELAY_DURING_SCROLL,
    ):
        """
        åˆå§‹åŒ–çˆ¬è™«

        Args:
            cookies_file: cookies æ–‡ä»¶è·¯å¾„
            headless: æ˜¯å¦ä½¿ç”¨æ— å¤´æ¨¡å¼
            max_posts_per_user: æ¯ä¸ªç”¨æˆ·æœ€å¤šçˆ¬å–çš„æ¨æ–‡æ•°é‡
            delay_between_users: ç”¨æˆ·é—´å»¶è¿ŸèŒƒå›´ (min, max) ç§’
            delay_during_scroll: æ»šåŠ¨æ—¶å»¶è¿ŸèŒƒå›´ (min, max) ç§’
        """
        if not PLAYWRIGHT_AVAILABLE:
            raise RuntimeError(
                "âŒ Playwright æœªå®‰è£…ã€‚è¯·è¿è¡Œ:\n"
                "   pip install playwright\n"
                "   playwright install chromium"
            )

        self.cookies_file = str(cookies_file or COOKIES_FILE)
        self.headless = headless
        self.max_posts_per_user = max_posts_per_user
        self.delay_between_users = delay_between_users
        self.delay_during_scroll = delay_during_scroll

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "users_processed": 0,
            "users_failed": 0,
            "tweets_scraped": 0,
            "tweets_new": 0,
            "tweets_duplicate": 0,
        }

        # åˆå§‹åŒ– Supabase å®¢æˆ·ç«¯
        self.supabase = get_supabase_client()
        if self.supabase:
            print("âœ… Supabase è¿æ¥æˆåŠŸ")
        else:
            print("âš ï¸ Supabase æœªè¿æ¥ï¼Œå°†åªæ‰“å°æ¨æ–‡è€Œä¸ä¿å­˜")

    def setup_mode(self, timeout: int = SETUP_LOGIN_TIMEOUT) -> bool:
        """
        Setup æ¨¡å¼: æ‰“å¼€æµè§ˆå™¨è®©ç”¨æˆ·æ‰‹åŠ¨ç™»å½•

        Args:
            timeout: ç­‰å¾…ç™»å½•çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            bool: ç™»å½•æˆåŠŸè¿”å› True
        """
        print("\n" + "=" * 60)
        print("ğŸ”§ SETUP MODE - è¯·æ‰‹åŠ¨ç™»å½• X.com")
        print("=" * 60)

        with sync_playwright() as p:
            browser = p.chromium.launch(
                headless=False,  # Setup æ¨¡å¼å¿…é¡»æœ‰å¤´
                args=BROWSER_ARGS,
            )

            context = browser.new_context(
                user_agent=random.choice(USER_AGENTS),
                viewport=BROWSER_VIEWPORT,
                locale=BROWSER_LOCALE,
                timezone_id=BROWSER_TIMEZONE,
            )

            page = context.new_page()
            self._add_stealth_scripts(page)

            try:
                print("ğŸ“± æ­£åœ¨æ‰“å¼€ X.com...")
                page.goto(
                    "https://x.com/login", wait_until="domcontentloaded", timeout=60000
                )

                print("\n" + "âš ï¸ " * 20)
                print("è¯·åœ¨æµè§ˆå™¨çª—å£ä¸­å®Œæˆç™»å½•ï¼")
                print(f"è¶…æ—¶æ—¶é—´: {timeout} ç§’")
                print("âš ï¸ " * 20 + "\n")

                # ç­‰å¾…ç”¨æˆ·å®Œæˆç™»å½•ï¼ˆæ£€æµ‹ä¸»é¡µå…ƒç´ ï¼‰
                try:
                    page.wait_for_selector(
                        '[data-testid="primaryColumn"]',
                        timeout=timeout * 1000,
                        state="visible",
                    )
                    print("âœ… æ£€æµ‹åˆ°å·²ç™»å½•ï¼")

                    # ä¿å­˜ cookies
                    cookies = context.cookies()
                    if save_cookies(cookies, self.cookies_file):
                        print("âœ… Setup å®Œæˆï¼ç°åœ¨å¯ä»¥è¿è¡Œ Batch Mode äº†ã€‚")
                        return True

                except Exception as e:
                    print(f"âŒ ç™»å½•è¶…æ—¶æˆ–å¤±è´¥: {e}")
                    return False

            finally:
                print("\næµè§ˆå™¨å°†åœ¨ 3 ç§’åå…³é—­...")
                time.sleep(3)
                browser.close()

        return False

    def _add_stealth_scripts(self, page: "Page") -> None:
        """æ·»åŠ åæ£€æµ‹è„šæœ¬"""
        page.add_init_script(
            """
            // éšè— webdriver å±æ€§
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            
            // æ¨¡æ‹ŸçœŸå®çš„ plugins
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5]
            });
            
            // æ¨¡æ‹ŸçœŸå®çš„ languages
            Object.defineProperty(navigator, 'languages', {
                get: () => ['en-US', 'en']
            });
            
            // éšè—è‡ªåŠ¨åŒ–ç—•è¿¹
            window.chrome = { runtime: {} };
        """
        )

    def _scrape_single_user(self, page: "Page", username: str) -> List[Dict]:
        """
        çˆ¬å–å•ä¸ªç”¨æˆ·çš„æ¨æ–‡å’Œ profile ä¿¡æ¯

        Args:
            page: Playwright é¡µé¢å¯¹è±¡
            username: ç”¨æˆ·å

        Returns:
            List[Dict]: çˆ¬å–åˆ°çš„æ¨æ–‡åˆ—è¡¨
        """
        clean_username = username.lstrip("@").strip()
        profile_url = f"https://x.com/{clean_username}"

        # ä½¿ç”¨æœç´¢ URL å¹¶æŒ‰æ—¶é—´æ’åºï¼ˆf=live è¡¨ç¤ºæœ€æ–°ï¼‰
        search_url = (
            f"https://x.com/search?q=from%3A{clean_username}&src=typed_query&f=live"
        )

        collected_tweets = []
        seen_texts: Set[str] = set()

        print(f"\nğŸ“ æ­£åœ¨è®¿é—® @{clean_username}...")

        try:
            # ========== ç¬¬ä¸€æ­¥ï¼šè®¿é—®ç”¨æˆ·ä¸»é¡µè·å– Profile ä¿¡æ¯ ==========
            page.goto(
                profile_url, wait_until="domcontentloaded", timeout=PAGE_LOAD_TIMEOUT
            )
            random_sleep(2, 4)

            # æ£€æµ‹æ˜¯å¦æˆåŠŸåŠ è½½ç”¨æˆ·é¡µé¢
            try:
                page.wait_for_selector(
                    "article", timeout=ELEMENT_WAIT_TIMEOUT, state="visible"
                )
            except Exception:
                print(f"   âš ï¸ æ— æ³•åŠ è½½ @{clean_username} çš„é¡µé¢ï¼ˆå¯èƒ½ä¸å­˜åœ¨æˆ–è¢«å°ç¦ï¼‰")
                return []

            # ========== æå–å¹¶ä¿å­˜ Profile ä¿¡æ¯ ==========
            profile_data = extract_user_profile(page)
            profile_data["username"] = clean_username  # ç¡®ä¿ç”¨æˆ·åæ­£ç¡®

            if self.supabase:
                if upsert_kol_profile(self.supabase, profile_data):
                    self.stats["profiles_updated"] = (
                        self.stats.get("profiles_updated", 0) + 1
                    )
                    # æ‰“å° profile ä¿¡æ¯
                    display_name = profile_data.get("display_name", clean_username)
                    followers = profile_data.get("followers_count", 0)
                    following = profile_data.get("following_count", 0)
                    posts = profile_data.get("posts_count", 0)
                    verified = profile_data.get("verification_type", "None")

                    # è®¤è¯å¾½ç« 
                    badge = ""
                    if verified == "Gold":
                        badge = "ğŸ¢"
                    elif verified == "Blue":
                        badge = "âœ“"
                    elif verified == "Grey":
                        badge = "ğŸ›ï¸"

                    print(f"   ğŸ‘¤ {display_name} {badge}")
                    print(
                        f"      ğŸ“Š ç²‰ä¸: {followers:,} | å…³æ³¨: {following:,} | æ¨æ–‡: {posts:,}"
                    )

                    # é¢å¤–ä¿¡æ¯
                    extras = []
                    if profile_data.get("avatar_url"):
                        extras.append("å¤´åƒâœ“")
                    if profile_data.get("banner_url"):
                        extras.append("èƒŒæ™¯âœ“")
                    if profile_data.get("location"):
                        extras.append(f"ğŸ“{profile_data['location']}")
                    if profile_data.get("join_date"):
                        extras.append(f"ğŸ“…{profile_data['join_date']}")
                    if profile_data.get("website"):
                        extras.append(f"ğŸ”—")

                    if extras:
                        print(f"      {' | '.join(extras)}")

            # ========== ç¬¬äºŒæ­¥ï¼šè·³è½¬åˆ°æœç´¢é¡µé¢è·å–æœ€æ–°æ¨æ–‡ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰==========
            print(f"   ğŸ” åˆ‡æ¢åˆ°æœ€æ–°æ¨æ–‡è§†å›¾ (æœç´¢: from:{clean_username})...")
            page.goto(
                search_url, wait_until="domcontentloaded", timeout=PAGE_LOAD_TIMEOUT
            )
            random_sleep(2, 4)

            # ç­‰å¾…æœç´¢ç»“æœåŠ è½½
            try:
                page.wait_for_selector(
                    "article", timeout=ELEMENT_WAIT_TIMEOUT, state="visible"
                )
            except Exception:
                # æˆªå›¾ä¿å­˜ï¼Œæ–¹ä¾¿è°ƒè¯•
                debug_path = f"debug_{clean_username}.png"
                try:
                    page.screenshot(path=debug_path)
                    print(f"   âš ï¸ æœç´¢ç»“æœä¸ºç©ºæˆ–åŠ è½½å¤±è´¥ï¼Œæˆªå›¾å·²ä¿å­˜: {debug_path}")
                except Exception:
                    print(f"   âš ï¸ æœç´¢ç»“æœä¸ºç©ºæˆ–åŠ è½½å¤±è´¥")

                # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯æç¤ºæˆ–éœ€è¦éªŒè¯
                page_content = page.content().lower()
                if "verify" in page_content or "captcha" in page_content:
                    print(f"   ğŸ”’ æ£€æµ‹åˆ°éªŒè¯ç /äººæœºéªŒè¯ï¼Œè¯·é‡æ–°è¿è¡Œ --setup ç™»å½•")
                elif "something went wrong" in page_content:
                    print(f"   âŒ é¡µé¢æ˜¾ç¤º 'Something went wrong'ï¼Œå¯èƒ½æ˜¯è´¦å·é—®é¢˜")
                elif "log in" in page_content or "sign in" in page_content:
                    print(f"   ğŸ”‘ éœ€è¦ç™»å½•ï¼Œè¯·åˆ é™¤ cookies æ–‡ä»¶å¹¶é‡æ–°è¿è¡Œ --setup")

                return []

            # æ»šåŠ¨å’Œçˆ¬å–æœ€æ–°æ¨æ–‡
            scroll_count = 0
            no_new_count = 0

            while (
                len(collected_tweets) < self.max_posts_per_user
                and scroll_count < DEFAULT_MAX_SCROLLS
            ):
                scroll_count += 1

                articles = page.query_selector_all("article")
                new_in_batch = 0

                for article in articles:
                    if len(collected_tweets) >= self.max_posts_per_user:
                        break

                    text = extract_tweet_text(article)

                    if text and text not in seen_texts:
                        seen_texts.add(text)
                        metadata = extract_tweet_metadata(article)

                        tweet_data = {
                            "username": clean_username,
                            "text": text,
                            **metadata,
                        }

                        collected_tweets.append(tweet_data)
                        new_in_batch += 1

                        # ä¿å­˜åˆ° Supabaseï¼ˆå« AI åˆ†æï¼‰
                        if self.supabase:
                            inserted, tweet_id = insert_tweet(self.supabase, tweet_data)
                            if inserted:
                                self.stats["tweets_new"] += 1
                                # æ˜¾ç¤ºæ¨æ–‡æ—¶é—´ï¼Œæ–¹ä¾¿ç¡®è®¤æ˜¯å¦æ˜¯æœ€æ–°æ¨æ–‡
                                created_at = metadata.get("created_at", "")
                                time_str = created_at[:16] if created_at else "æœªçŸ¥æ—¶é—´"
                                print(
                                    f"   âœ… [{len(collected_tweets)}/{self.max_posts_per_user}] ğŸ•{time_str} | {text[:40]}..."
                                )
                            else:
                                self.stats["tweets_duplicate"] += 1
                                print(
                                    f"   ğŸ“‹ [{len(collected_tweets)}/{self.max_posts_per_user}] å·²å­˜åœ¨: {text[:40]}..."
                                )
                        else:
                            created_at = metadata.get("created_at", "")
                            time_str = created_at[:16] if created_at else "æœªçŸ¥æ—¶é—´"
                            print(
                                f"   ğŸ“ [{len(collected_tweets)}/{self.max_posts_per_user}] ğŸ•{time_str} | {text[:40]}..."
                            )

                if new_in_batch == 0:
                    no_new_count += 1
                    if no_new_count >= 2:
                        break
                else:
                    no_new_count = 0

                if len(collected_tweets) >= self.max_posts_per_user:
                    break

                # æ»šåŠ¨é¡µé¢
                page.evaluate(
                    """
                    window.scrollBy({
                        top: window.innerHeight * 0.8,
                        behavior: 'smooth'
                    });
                """
                )

                random_sleep(*self.delay_during_scroll)

                try:
                    page.wait_for_load_state(
                        "networkidle", timeout=NETWORK_IDLE_TIMEOUT
                    )
                except Exception:
                    pass

            self.stats["tweets_scraped"] += len(collected_tweets)

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨æ–‡ï¼Œæˆªå›¾è°ƒè¯•
            if len(collected_tweets) == 0:
                debug_path = f"debug_empty_{clean_username}.png"
                try:
                    page.screenshot(path=debug_path)
                    print(f"   âš ï¸ æœªæ‰¾åˆ°æ¨æ–‡ï¼Œæˆªå›¾å·²ä¿å­˜: {debug_path}")
                except Exception:
                    pass
            else:
                print(
                    f"   ğŸ“Š @{clean_username}: çˆ¬å– {len(collected_tweets)} æ¡æœ€æ–°æ¨æ–‡"
                )

        except Exception as e:
            print(f"   âŒ çˆ¬å– @{clean_username} å¤±è´¥: {e}")
            # æˆªå›¾ä¿å­˜é”™è¯¯ç°åœº
            try:
                page.screenshot(path=f"error_{clean_username}.png")
                print(f"   ğŸ“¸ é”™è¯¯æˆªå›¾å·²ä¿å­˜: error_{clean_username}.png")
            except Exception:
                pass
            self.stats["users_failed"] += 1

        return collected_tweets

    def batch_scrape(self, usernames: List[str]) -> Dict:
        """
        æ‰¹é‡çˆ¬å– KOL æ¨æ–‡

        Args:
            usernames: ç”¨æˆ·ååˆ—è¡¨

        Returns:
            Dict: ç»Ÿè®¡ä¿¡æ¯
        """
        if not usernames:
            print("âŒ æ²¡æœ‰è¦çˆ¬å–çš„ç”¨æˆ·")
            return self.stats

        # æ£€æŸ¥ cookies
        cookies = load_cookies(self.cookies_file)
        if cookies is None:
            print("\nâŒ æœªæ‰¾åˆ° cookies æ–‡ä»¶ï¼")
            print("è¯·å…ˆè¿è¡Œ Setup Mode è¿›è¡Œç™»å½•:")
            print("   python -m app.services.scraper --setup")
            return self.stats

        print("\n" + "=" * 60)
        print(f"ğŸš€ BATCH MODE - å¼€å§‹æ‰¹é‡çˆ¬å–")
        print(f"ğŸ“‹ ç›®æ ‡: {len(usernames)} ä¸ª KOL")
        print(f"ğŸ“ æ¯ç”¨æˆ·æœ€å¤š: {self.max_posts_per_user} æ¡æ¨æ–‡")
        print(f"ğŸ’¾ å­˜å‚¨: {'Supabase' if self.supabase else 'ä»…æ‰“å°'}")
        print("=" * 60)

        with sync_playwright() as p:
            browser = p.chromium.launch(
                headless=self.headless,
                args=BROWSER_ARGS,
            )

            context = browser.new_context(
                user_agent=random.choice(USER_AGENTS),
                viewport=BROWSER_VIEWPORT,
                locale=BROWSER_LOCALE,
                timezone_id=BROWSER_TIMEZONE,
            )

            # åŠ è½½ cookies
            context.add_cookies(cookies)

            page = context.new_page()
            self._add_stealth_scripts(page)

            try:
                for i, username in enumerate(usernames, 1):
                    print(f"\n[{i}/{len(usernames)}] ğŸ¯ @{username}")

                    self._scrape_single_user(page, username)
                    self.stats["users_processed"] += 1

                    # ç”¨æˆ·é—´å»¶è¿Ÿï¼ˆæœ€åä¸€ä¸ªç”¨æˆ·ä¸éœ€è¦ï¼‰
                    if i < len(usernames):
                        random_sleep(
                            *self.delay_between_users, f"åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªç”¨æˆ·å‰ç­‰å¾…"
                        )

            except KeyboardInterrupt:
                print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜æ•°æ®...")

            except Exception as e:
                print(f"\nâŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")

            finally:
                # æ›´æ–° cookiesï¼ˆå¯èƒ½å·²åˆ·æ–°ï¼‰
                try:
                    new_cookies = context.cookies()
                    save_cookies(new_cookies, self.cookies_file)
                except Exception:
                    pass

                browser.close()

        # æ‰“å°æœ€ç»ˆç»Ÿè®¡
        self._print_final_stats()

        return self.stats

    def _print_final_stats(self) -> None:
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("ğŸ“Š çˆ¬å–å®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯:")
        print("=" * 60)
        print(f"  âœ… å¤„ç†ç”¨æˆ·: {self.stats['users_processed']}")
        print(f"  âŒ å¤±è´¥ç”¨æˆ·: {self.stats['users_failed']}")
        print(f"  ğŸ‘¤ æ›´æ–° Profile: {self.stats.get('profiles_updated', 0)}")
        print(f"  ğŸ“ çˆ¬å–æ¨æ–‡: {self.stats['tweets_scraped']}")
        print(f"  ğŸ†• æ–°å¢æ¨æ–‡: {self.stats['tweets_new']}")
        print(f"  ğŸ“‹ é‡å¤æ¨æ–‡: {self.stats['tweets_duplicate']}")
        print("=" * 60)

        # æ•°æ®åº“ç»Ÿè®¡
        if self.supabase:
            db_stats = get_stats(self.supabase)
            print(f"\nğŸ“¦ Supabase æ•°æ®åº“æ€»è®¡: {db_stats['total']} æ¡æ¨æ–‡")

            # ç»Ÿè®¡ kol_profiles è¡¨æ•°é‡
            try:
                profiles_result = (
                    self.supabase.table("kol_profiles")
                    .select("username, verification_type", count="exact")
                    .execute()
                )
                total_profiles = profiles_result.count or 0
                print(f"ğŸ‘¤ KOL Profiles: {total_profiles} ä¸ª")

                # æŒ‰è®¤è¯ç±»å‹ç»Ÿè®¡
                if profiles_result.data:
                    verified_counts = {}
                    for profile in profiles_result.data:
                        v_type = profile.get("verification_type") or "None"
                        verified_counts[v_type] = verified_counts.get(v_type, 0) + 1
                    if verified_counts and any(k != "None" for k in verified_counts):
                        badges = {"Gold": "ğŸ¢", "Blue": "âœ“", "Grey": "ğŸ›ï¸", "None": "â—‹"}
                        parts = [
                            f"{badges.get(k, '')} {k}: {v}"
                            for k, v in verified_counts.items()
                        ]
                        print(f"   è®¤è¯: {' | '.join(parts)}")
            except Exception:
                pass

    def close(self) -> None:
        """å…³é—­èµ„æºï¼ˆä¿ç•™æ¥å£å…¼å®¹æ€§ï¼‰"""
        pass
