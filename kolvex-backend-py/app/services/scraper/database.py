"""
Supabase æ•°æ®åº“æ“ä½œ
"""

import os
import json
import hashlib
from typing import Dict, Optional, Tuple
from datetime import datetime, timedelta, timezone

# Supabase ç›¸å…³å¯¼å…¥
try:
    from supabase import create_client, Client

    SUPABASE_AVAILABLE = True
except ImportError:
    SUPABASE_AVAILABLE = False
    Client = None

from .config import DEFAULT_TWEET_MAX_AGE_DAYS


def get_supabase_client() -> Optional[Client]:
    """
    è·å– Supabase å®¢æˆ·ç«¯

    Returns:
        Optional[Client]: Supabase å®¢æˆ·ç«¯ï¼Œå¦‚æœæœªé…ç½®è¿”å› None
    """
    if not SUPABASE_AVAILABLE:
        print("âš ï¸ Supabase æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install supabase")
        return None

    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    from dotenv import load_dotenv

    load_dotenv()

    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_SERVICE_KEY") or os.getenv("SUPABASE_KEY")

    if not supabase_url or not supabase_key:
        print(
            "âš ï¸ Supabase é…ç½®æœªæ‰¾åˆ°ï¼Œè¯·è®¾ç½® SUPABASE_URL å’Œ SUPABASE_SERVICE_KEY ç¯å¢ƒå˜é‡"
        )
        return None

    return create_client(supabase_url, supabase_key)


def compute_tweet_hash(text: str, username: str) -> str:
    """
    è®¡ç®—æ¨æ–‡çš„å”¯ä¸€å“ˆå¸Œå€¼

    Args:
        text: æ¨æ–‡æ–‡æœ¬
        username: ç”¨æˆ·å

    Returns:
        str: SHA256 å“ˆå¸Œå€¼çš„å‰ 16 ä½
    """
    content = f"{username}:{text}"
    return hashlib.sha256(content.encode()).hexdigest()[:16]


def tweet_exists(client: Client, tweet_hash: str) -> bool:
    """
    æ£€æŸ¥æ¨æ–‡æ˜¯å¦å·²å­˜åœ¨äºæ•°æ®åº“ä¸­

    Args:
        client: Supabase å®¢æˆ·ç«¯
        tweet_hash: æ¨æ–‡å“ˆå¸Œå€¼

    Returns:
        bool: å¦‚æœå­˜åœ¨è¿”å› True
    """
    try:
        result = (
            client.table("kol_tweets")
            .select("id")
            .eq("tweet_hash", tweet_hash)
            .limit(1)
            .execute()
        )
        return len(result.data) > 0
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥æ¨æ–‡æ˜¯å¦å­˜åœ¨å¤±è´¥: {e}")
        return False


def insert_tweet(
    client: Client,
    tweet_data: Dict,
    max_age_days: int = DEFAULT_TWEET_MAX_AGE_DAYS,
    enable_ai_analysis: bool = True,
) -> Tuple[bool, Optional[int]]:
    """
    æ’å…¥æ¨æ–‡åˆ° Supabase æ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨ä¸”ä¸å¤ªæ—§ï¼‰ï¼Œå¹¶è¿›è¡Œ AI åˆ†æ

    Args:
        client: Supabase å®¢æˆ·ç«¯
        tweet_data: æ¨æ–‡æ•°æ®å­—å…¸ï¼ŒåŒ…å«:
            - username: ç”¨æˆ·å
            - text: æ¨æ–‡æ–‡æœ¬
            - created_at: åˆ›å»ºæ—¶é—´
            - permalink: æ¨æ–‡é“¾æ¥
            - avatar_url: KOL å¤´åƒ URL
            - media_urls: åª’ä½“ URL åˆ—è¡¨
            - is_repost: æ˜¯å¦æ˜¯è½¬å‘
            - original_author: åŸä½œè€…
            - reply_count, repost_count, like_count, bookmark_count, views_count
        max_age_days: æœ€å¤§æ¨æ–‡å¹´é¾„ï¼ˆå¤©ï¼‰ï¼Œè¶…è¿‡æ­¤å¤©æ•°çš„æ¨æ–‡ä¸ä¼šè¢«æ’å…¥
        enable_ai_analysis: æ˜¯å¦å¯ç”¨ AI åˆ†æï¼ˆé»˜è®¤ Trueï¼‰

    Returns:
        Tuple[bool, Optional[int]]: (æ’å…¥æˆåŠŸè¿”å› Trueï¼Œæ¨æ–‡ ID æˆ– None)
    """
    # æ£€æŸ¥æ¨æ–‡æ—¶é—´ï¼Œå¦‚æœå¤ªæ—§å°±è·³è¿‡
    created_at_str = tweet_data.get("created_at")
    if created_at_str:
        try:
            # è§£æ ISO æ ¼å¼æ—¶é—´
            if created_at_str.endswith("Z"):
                created_at_str = created_at_str[:-1] + "+00:00"
            tweet_time = datetime.fromisoformat(created_at_str.replace("Z", "+00:00"))

            # å¦‚æœæ˜¯ naive datetimeï¼Œå‡è®¾ä¸º UTC
            if tweet_time.tzinfo is None:
                tweet_time = tweet_time.replace(tzinfo=timezone.utc)

            cutoff_time = datetime.now(timezone.utc) - timedelta(days=max_age_days)

            if tweet_time < cutoff_time:
                print(
                    f"   â­ï¸ è·³è¿‡æ—§æ¨æ–‡ ({created_at_str[:10]}): {tweet_data['text'][:30]}..."
                )
                return False, None
        except Exception:
            # è§£æå¤±è´¥å°±ç»§ç»­æ’å…¥
            pass

    tweet_hash = compute_tweet_hash(tweet_data["text"], tweet_data["username"])

    if tweet_exists(client, tweet_hash):
        return False, None

    # è¿›è¡Œ AI åˆ†æï¼ˆåœ¨æ’å…¥å‰ï¼‰
    ai_analysis = None
    if enable_ai_analysis:
        ai_analysis = _perform_ai_analysis(tweet_data["text"])

    try:
        # å¤„ç† media_urls - è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²å­˜å‚¨
        media_urls = tweet_data.get("media_urls", [])
        media_urls_json = json.dumps(media_urls) if media_urls else None

        data = {
            "username": tweet_data["username"],
            "tweet_text": tweet_data["text"],
            "tweet_hash": tweet_hash,
            "created_at": tweet_data.get("created_at"),
            "permalink": tweet_data.get("permalink"),
            # æ–°å¢å­—æ®µ
            "avatar_url": tweet_data.get("avatar_url"),
            "media_urls": media_urls_json,
            "is_repost": tweet_data.get("is_repost", False),
            "original_author": tweet_data.get("original_author"),
            # äº’åŠ¨æ•°æ®
            "like_count": tweet_data.get("like_count", 0),
            "retweet_count": tweet_data.get("repost_count", 0),  # å…¼å®¹æ—§å­—æ®µå
            "reply_count": tweet_data.get("reply_count", 0),
            "bookmark_count": tweet_data.get("bookmark_count", 0),
            "views_count": tweet_data.get("views_count", 0),
            # å…ƒæ•°æ®
            "scraped_at": datetime.now(timezone.utc).isoformat(),
        }

        # æ·»åŠ  AI åˆ†æç»“æœ
        if ai_analysis:
            stock_related_data = ai_analysis.get("is_stock_related", {})
            data.update(
                {
                    # æƒ…æ„Ÿåˆ†æ
                    "ai_sentiment": ai_analysis.get("sentiment", {}).get("sentiment"),
                    "ai_sentiment_confidence": ai_analysis.get("sentiment", {}).get(
                        "confidence"
                    ),
                    "ai_sentiment_reasoning": ai_analysis.get("sentiment", {}).get(
                        "reasoning"
                    ),
                    # è‚¡ç¥¨ä»£ç å’Œæ ‡ç­¾ (JSONB)
                    "ai_tickers": ai_analysis.get("tickers", []),
                    "ai_tags": ai_analysis.get("tags", []),
                    # æ‘˜è¦å’ŒæŠ•èµ„ä¿¡å·
                    "ai_summary": ai_analysis.get("summary"),
                    "ai_trading_signal": ai_analysis.get("trading_signal"),
                    # è‚¡å¸‚ç›¸å…³æ€§
                    "ai_is_stock_related": stock_related_data.get(
                        "is_stock_related", False
                    ),
                    "ai_stock_related_confidence": stock_related_data.get("confidence"),
                    "ai_stock_related_reason": stock_related_data.get("reason"),
                    # å…ƒæ•°æ®
                    "ai_analyzed_at": ai_analysis.get("analyzed_at"),
                    "ai_model": ai_analysis.get("model"),
                }
            )

        result = client.table("kol_tweets").insert(data).execute()
        # è·å–æ’å…¥çš„æ¨æ–‡ ID
        tweet_id = result.data[0]["id"] if result.data else None
        return True, tweet_id
    except Exception as e:
        # å¯èƒ½æ˜¯å”¯ä¸€çº¦æŸå†²çªï¼ˆå¹¶å‘æƒ…å†µï¼‰
        if "duplicate" in str(e).lower() or "unique" in str(e).lower():
            return False, None
        print(f"âš ï¸ æ’å…¥æ¨æ–‡å¤±è´¥: {e}")
        return False, None


# AI åˆ†æå™¨å•ä¾‹ï¼ˆé¿å…é‡å¤åˆ›å»ºï¼‰
_ai_analyzer = None


def _get_ai_analyzer():
    """è·å– AI åˆ†æå™¨å•ä¾‹"""
    global _ai_analyzer
    if _ai_analyzer is None:
        try:
            from app.services.ai import TweetAnalyzerSync, OllamaClientSync

            client = OllamaClientSync()
            # å…ˆæ£€æŸ¥ AI æœåŠ¡æ˜¯å¦å¯ç”¨
            if client.health_check():
                _ai_analyzer = TweetAnalyzerSync(client)
                print("ğŸ¤– AI åˆ†æå™¨å·²åˆå§‹åŒ–")
            else:
                print("âš ï¸ AI æœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡ AI åˆ†æ")
                _ai_analyzer = False  # æ ‡è®°ä¸ºä¸å¯ç”¨
        except Exception as e:
            print(f"âš ï¸ AI åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            _ai_analyzer = False
    return _ai_analyzer if _ai_analyzer else None


def _perform_ai_analysis(tweet_text: str) -> Optional[Dict]:
    """
    æ‰§è¡Œ AI åˆ†æï¼ˆåŒæ­¥ï¼‰

    Args:
        tweet_text: æ¨æ–‡æ–‡æœ¬

    Returns:
        Optional[Dict]: åˆ†æç»“æœï¼Œå¤±è´¥è¿”å› None
    """
    analyzer = _get_ai_analyzer()
    if not analyzer:
        return None

    try:
        analysis = analyzer.basic_analysis(tweet_text)
        sentiment = analysis.get("sentiment", {}).get("sentiment", "neutral")
        tickers = analysis.get("tickers", [])
        print(f"   ğŸ¤– AI: {sentiment} | è‚¡ç¥¨: {tickers if tickers else 'æ— '}")
        return analysis
    except Exception as e:
        print(f"   âš ï¸ AI åˆ†æå¤±è´¥: {e}")
        return None


def upsert_kol_profile(client: Client, profile_data: Dict) -> bool:
    """
    æ’å…¥æˆ–æ›´æ–° KOL profile åˆ° Supabase çš„ kol_profiles è¡¨

    Args:
        client: Supabase å®¢æˆ·ç«¯
        profile_data: å®Œæ•´çš„ profile æ•°æ®å­—å…¸

    Returns:
        bool: æ“ä½œæˆåŠŸè¿”å› True
    """
    try:
        data = {
            # æ ¸å¿ƒèº«ä»½ä¿¡æ¯
            "username": profile_data["username"],
            "rest_id": profile_data.get("rest_id"),
            "display_name": profile_data.get("display_name"),
            # è®¤è¯çŠ¶æ€
            "is_verified": profile_data.get("is_verified", False),
            "verification_type": profile_data.get("verification_type", "None"),
            # å½±å“åŠ›æŒ‡æ ‡
            "followers_count": profile_data.get("followers_count", 0),
            "following_count": profile_data.get("following_count", 0),
            "posts_count": profile_data.get("posts_count", 0),
            # æ—¶é—´ä¿¡æ¯
            "join_date": profile_data.get("join_date"),
            # å¤–éƒ¨é“¾æ¥ä¸ä½ç½®
            "location": profile_data.get("location"),
            "website": profile_data.get("website"),
            "bio": profile_data.get("bio"),
            # è§†è§‰ç´ æ
            "avatar_url": profile_data.get("avatar_url"),
            "banner_url": profile_data.get("banner_url"),
            # å…ƒæ•°æ®
            "is_active": True,
            "updated_at": datetime.now(timezone.utc).isoformat(),
        }
        # ä½¿ç”¨ upsertï¼Œå¦‚æœ username å·²å­˜åœ¨åˆ™æ›´æ–°
        client.table("kol_profiles").upsert(data, on_conflict="username").execute()
        return True
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜ KOL profile å¤±è´¥: {e}")
        return False


# ä¿ç•™æ—§å‡½æ•°åä½œä¸ºåˆ«åï¼Œä¿æŒå…¼å®¹æ€§
upsert_user_profile = upsert_kol_profile


def get_stats(client: Client) -> Dict:
    """
    è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯

    Returns:
        Dict: åŒ…å«æ€»æ•°ã€å„ç”¨æˆ·æ•°é‡ç­‰ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        # æ€»æ¨æ–‡æ•°
        total_result = client.table("kol_tweets").select("id", count="exact").execute()
        total = total_result.count or 0

        # ç®€å•æŸ¥è¯¢å„ç”¨æˆ·æ¨æ–‡æ•°
        by_user = {}
        try:
            users_result = client.table("kol_tweets").select("username").execute()
            for row in users_result.data:
                username = row["username"]
                by_user[username] = by_user.get(username, 0) + 1
        except Exception:
            pass

        return {
            "total": total,
            "by_user": dict(sorted(by_user.items(), key=lambda x: x[1], reverse=True)),
        }
    except Exception as e:
        print(f"âš ï¸ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return {"total": 0, "by_user": {}}
