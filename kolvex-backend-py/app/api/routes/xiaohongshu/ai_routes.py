"""
å°çº¢ä¹¦å¸–å­ AI åˆ†æ API è·¯ç”±
æä¾› AI åˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬æƒ…æ„Ÿåˆ†æã€è‚¡ç¥¨ä»£ç æå–ã€æ‘˜è¦ç”Ÿæˆç­‰
"""

from fastapi import APIRouter, HTTPException, Query, BackgroundTasks
from typing import Dict, List, Optional
from datetime import datetime, timezone

from app.services.xiaohongshu import get_supabase_client
from app.services.ai import TweetAnalyzer, OllamaClient

from .schemas import (
    AIAnalysisRequest,
    AIAnalysisResponse,
    BatchAnalysisRequest,
)

router = APIRouter()


# ============================================================
# AI åˆ†æç«¯ç‚¹
# ============================================================


async def _analyze_post_content(content: str, title: str = "") -> Dict:
    """
    å†…éƒ¨å‡½æ•°ï¼šå¯¹å¸–å­å†…å®¹è¿›è¡Œ AI åˆ†æ
    """
    full_text = f"{title}\n\n{content}" if title else content

    async with OllamaClient() as client:
        analyzer = TweetAnalyzer(client)
        result = await analyzer.full_analysis(full_text)
        return result


def _update_post_with_analysis(supabase, post_id: int, analysis: Dict) -> bool:
    """
    å†…éƒ¨å‡½æ•°ï¼šå°† AI åˆ†æç»“æœæ›´æ–°åˆ°æ•°æ®åº“
    """
    try:
        sentiment_data = analysis.get("sentiment", {})
        is_stock_data = analysis.get("is_stock_related", {})
        trading_signal = analysis.get("trading_signal", {})

        update_data = {
            "ai_sentiment": sentiment_data.get("sentiment", "neutral"),
            "ai_sentiment_confidence": sentiment_data.get("confidence", 0.0),
            "ai_sentiment_reasoning": sentiment_data.get("reasoning", ""),
            "ai_tickers": analysis.get("tickers", []),
            "ai_tags": analysis.get("tags", []),
            "ai_summary": analysis.get("summary", ""),
            "ai_trading_signal": trading_signal.get("action"),
            "ai_is_stock_related": is_stock_data.get("is_stock_related", False),
            "ai_stock_related_confidence": is_stock_data.get("confidence", 0.0),
            "ai_stock_related_reason": is_stock_data.get("reason", ""),
            "ai_analyzed_at": datetime.now(timezone.utc).isoformat(),
            "ai_model": analysis.get("model", "unknown"),
        }

        supabase.table("xhs_posts").update(update_data).eq("id", post_id).execute()
        return True
    except Exception as e:
        print(f"âŒ æ›´æ–°åˆ†æç»“æœå¤±è´¥: {e}")
        return False


@router.post("/analyze/{note_id}", response_model=AIAnalysisResponse)
async def analyze_single_post(
    note_id: str,
    force: bool = Query(False, description="æ˜¯å¦å¼ºåˆ¶é‡æ–°åˆ†æ"),
):
    """
    ğŸ¤– AI åˆ†æå•ä¸ªå¸–å­

    å¯¹æŒ‡å®šå¸–å­è¿›è¡Œ AI åˆ†æï¼Œæå–ï¼š
    - æƒ…æ„Ÿå€¾å‘ (bullish/bearish/neutral)
    - è‚¡ç¥¨ä»£ç  (å¦‚ NVDA, TSLA)
    - å…³é”®æ ‡ç­¾
    - å†…å®¹æ‘˜è¦
    - äº¤æ˜“ä¿¡å·
    - æ˜¯å¦ä¸è‚¡ç¥¨ç›¸å…³

    å‚æ•°ï¼š
    - note_id: å°çº¢ä¹¦ç¬”è®° ID
    - force: æ˜¯å¦å¼ºåˆ¶é‡æ–°åˆ†æï¼ˆå³ä½¿å·²æœ‰åˆ†æç»“æœï¼‰
    """
    supabase = get_supabase_client()
    if not supabase:
        raise HTTPException(status_code=503, detail="Supabase æœªè¿æ¥")

    try:
        # è·å–å¸–å­
        result = (
            supabase.table("xhs_posts")
            .select("*")
            .eq("note_id", note_id)
            .limit(1)
            .execute()
        )

        if not result.data:
            raise HTTPException(status_code=404, detail=f"å¸–å­ä¸å­˜åœ¨: {note_id}")

        post = result.data[0]

        # æ£€æŸ¥æ˜¯å¦å·²åˆ†æä¸”ä¸å¼ºåˆ¶é‡æ–°åˆ†æ
        if post.get("ai_analyzed_at") and not force:
            return AIAnalysisResponse(
                success=True,
                note_id=note_id,
                sentiment=post.get("ai_sentiment"),
                sentiment_confidence=post.get("ai_sentiment_confidence"),
                sentiment_reasoning=post.get("ai_sentiment_reasoning"),
                tickers=post.get("ai_tickers"),
                tags=post.get("ai_tags"),
                summary=post.get("ai_summary"),
                trading_signal=post.get("ai_trading_signal"),
                is_stock_related=post.get("ai_is_stock_related", False),
                stock_related_confidence=post.get("ai_stock_related_confidence"),
                analyzed_at=post.get("ai_analyzed_at"),
                model=post.get("ai_model"),
            )

        # æ‰§è¡Œ AI åˆ†æ
        content = post.get("content", "")
        title = post.get("title", "")

        if not content and not title:
            raise HTTPException(status_code=400, detail="å¸–å­å†…å®¹ä¸ºç©ºï¼Œæ— æ³•åˆ†æ")

        analysis = await _analyze_post_content(content, title)

        # æ›´æ–°æ•°æ®åº“
        _update_post_with_analysis(supabase, post["id"], analysis)

        sentiment_data = analysis.get("sentiment", {})
        is_stock_data = analysis.get("is_stock_related", {})
        trading_signal = analysis.get("trading_signal", {})

        return AIAnalysisResponse(
            success=True,
            note_id=note_id,
            sentiment=sentiment_data.get("sentiment"),
            sentiment_confidence=sentiment_data.get("confidence"),
            sentiment_reasoning=sentiment_data.get("reasoning"),
            tickers=analysis.get("tickers"),
            tags=analysis.get("tags"),
            summary=analysis.get("summary"),
            trading_signal=trading_signal.get("action"),
            is_stock_related=is_stock_data.get("is_stock_related", False),
            stock_related_confidence=is_stock_data.get("confidence"),
            analyzed_at=analysis.get("analyzed_at"),
            model=analysis.get("model"),
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")


async def _batch_analyze_posts(supabase, posts: List[Dict], force: bool = False):
    """
    åå°æ‰¹é‡åˆ†æå¸–å­
    """
    analyzed_count = 0
    failed_count = 0

    for post in posts:
        try:
            # è·³è¿‡å·²åˆ†æçš„ï¼ˆé™¤éå¼ºåˆ¶ï¼‰
            if post.get("ai_analyzed_at") and not force:
                continue

            content = post.get("content", "")
            title = post.get("title", "")

            if not content and not title:
                continue

            print(f"ğŸ¤– åˆ†æå¸–å­: {post.get('note_id', post['id'])} - {title[:30]}...")

            analysis = await _analyze_post_content(content, title)

            if _update_post_with_analysis(supabase, post["id"], analysis):
                analyzed_count += 1
                is_stock = analysis.get("is_stock_related", {}).get(
                    "is_stock_related", False
                )
                sentiment = analysis.get("sentiment", {}).get("sentiment", "neutral")
                tickers = analysis.get("tickers", [])
                print(
                    f"  âœ… å®Œæˆ | è‚¡ç¥¨ç›¸å…³: {is_stock} | æƒ…æ„Ÿ: {sentiment} | ä»£ç : {tickers}"
                )
            else:
                failed_count += 1

        except Exception as e:
            print(f"  âŒ åˆ†æå¤±è´¥: {e}")
            failed_count += 1

    print(f"\nğŸ“Š æ‰¹é‡åˆ†æå®Œæˆ: æˆåŠŸ {analyzed_count}, å¤±è´¥ {failed_count}")
    return {"analyzed": analyzed_count, "failed": failed_count}


@router.post("/analyze-batch", response_model=Dict)
async def analyze_batch_posts(
    request: BatchAnalysisRequest,
    background_tasks: BackgroundTasks,
):
    """
    ğŸ¤– æ‰¹é‡ AI åˆ†æå¸–å­

    åå°ä»»åŠ¡æ‰¹é‡åˆ†æå¤šä¸ªå¸–å­ï¼Œè¿”å›ä»»åŠ¡çŠ¶æ€ã€‚

    å‚æ•°ï¼š
    - limit: åˆ†ææ•°é‡é™åˆ¶ (é»˜è®¤: 10, æœ€å¤§: 50)
    - force: æ˜¯å¦å¼ºåˆ¶é‡æ–°åˆ†æ
    - only_unanalyzed: æ˜¯å¦åªåˆ†ææœªåˆ†æçš„å¸–å­
    """
    supabase = get_supabase_client()
    if not supabase:
        raise HTTPException(status_code=503, detail="Supabase æœªè¿æ¥")

    try:
        # æ„å»ºæŸ¥è¯¢
        query = supabase.table("xhs_posts").select("*").order("scraped_at", desc=True)

        if request.only_unanalyzed:
            query = query.is_("ai_analyzed_at", "null")

        result = query.limit(request.limit).execute()
        posts = result.data or []

        if not posts:
            return {
                "success": True,
                "message": "æ²¡æœ‰éœ€è¦åˆ†æçš„å¸–å­",
                "total": 0,
            }

        # å¯åŠ¨åå°ä»»åŠ¡
        background_tasks.add_task(_batch_analyze_posts, supabase, posts, request.force)

        return {
            "success": True,
            "message": f"å·²å¯åŠ¨æ‰¹é‡åˆ†æä»»åŠ¡ï¼Œå…± {len(posts)} ä¸ªå¸–å­",
            "total": len(posts),
            "status": "processing",
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨åˆ†æä»»åŠ¡å¤±è´¥: {str(e)}")


@router.get("/analysis-stats", response_model=Dict)
def get_analysis_stats():
    """
    ğŸ“Š è·å– AI åˆ†æç»Ÿè®¡

    è¿”å› AI åˆ†æçš„ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    - å·²åˆ†æ/æœªåˆ†æå¸–å­æ•°é‡
    - æƒ…æ„Ÿåˆ†å¸ƒ
    - è‚¡ç¥¨ç›¸å…³æ€§åˆ†å¸ƒ
    - çƒ­é—¨è‚¡ç¥¨ä»£ç 
    """
    supabase = get_supabase_client()
    if not supabase:
        raise HTTPException(status_code=503, detail="Supabase æœªè¿æ¥")

    try:
        # æ€»æ•°
        total_result = supabase.table("xhs_posts").select("id", count="exact").execute()
        total_count = total_result.count or 0

        # å·²åˆ†ææ•°é‡
        analyzed_result = (
            supabase.table("xhs_posts")
            .select("id", count="exact")
            .not_.is_("ai_analyzed_at", "null")
            .execute()
        )
        analyzed_count = analyzed_result.count or 0

        # è‚¡ç¥¨ç›¸å…³æ•°é‡
        stock_related_result = (
            supabase.table("xhs_posts")
            .select("id", count="exact")
            .eq("ai_is_stock_related", True)
            .execute()
        )
        stock_related_count = stock_related_result.count or 0

        # æƒ…æ„Ÿåˆ†å¸ƒ
        bullish_result = (
            supabase.table("xhs_posts")
            .select("id", count="exact")
            .eq("ai_sentiment", "bullish")
            .execute()
        )
        bearish_result = (
            supabase.table("xhs_posts")
            .select("id", count="exact")
            .eq("ai_sentiment", "bearish")
            .execute()
        )
        neutral_result = (
            supabase.table("xhs_posts")
            .select("id", count="exact")
            .eq("ai_sentiment", "neutral")
            .execute()
        )

        return {
            "success": True,
            "stats": {
                "total_posts": total_count,
                "analyzed_posts": analyzed_count,
                "unanalyzed_posts": total_count - analyzed_count,
                "stock_related_posts": stock_related_count,
                "sentiment_distribution": {
                    "bullish": bullish_result.count or 0,
                    "bearish": bearish_result.count or 0,
                    "neutral": neutral_result.count or 0,
                },
                "analysis_rate": (
                    round(analyzed_count / total_count * 100, 2)
                    if total_count > 0
                    else 0
                ),
            },
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")


@router.get("/top-tickers", response_model=Dict)
def get_top_tickers(
    limit: int = Query(10, ge=1, le=50, description="è¿”å›æ•°é‡"),
):
    """
    ğŸ“ˆ è·å–çƒ­é—¨è‚¡ç¥¨ä»£ç 

    è¿”å›è¢«æåŠæœ€å¤šçš„è‚¡ç¥¨ä»£ç åŠå…¶å¸–å­æ•°é‡
    """
    supabase = get_supabase_client()
    if not supabase:
        raise HTTPException(status_code=503, detail="Supabase æœªè¿æ¥")

    try:
        # è·å–æ‰€æœ‰æœ‰ tickers çš„å¸–å­
        result = (
            supabase.table("xhs_posts")
            .select("ai_tickers")
            .not_.is_("ai_tickers", "null")
            .execute()
        )

        # ç»Ÿè®¡ ticker å‡ºç°æ¬¡æ•°
        ticker_counts = {}
        for row in result.data or []:
            tickers = row.get("ai_tickers", [])
            if tickers:
                for ticker in tickers:
                    ticker_counts[ticker] = ticker_counts.get(ticker, 0) + 1

        # æ’åºå¹¶å– top N
        sorted_tickers = sorted(
            ticker_counts.items(), key=lambda x: x[1], reverse=True
        )[:limit]

        return {
            "success": True,
            "tickers": [{"ticker": t[0], "count": t[1]} for t in sorted_tickers],
            "total_unique_tickers": len(ticker_counts),
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–çƒ­é—¨ä»£ç å¤±è´¥: {str(e)}")
