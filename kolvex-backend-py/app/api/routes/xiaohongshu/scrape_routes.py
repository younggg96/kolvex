"""
å°çº¢ä¹¦çˆ¬å– API è·¯ç”±
æä¾›å°çº¢ä¹¦ç¾è‚¡å¸–å­çˆ¬å–ç›¸å…³çš„ REST API ç«¯ç‚¹

æ³¨æ„ï¼šAPI ä½¿ç”¨æ— ç•Œé¢æ¨¡å¼çˆ¬å–ï¼Œéœ€è¦é¢„å…ˆç™»å½•ä¿å­˜ cookiesã€‚
ç™»å½•å‘½ä»¤ï¼špython -m app.services.xiaohongshu --login
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from typing import List, Dict

from app.services.xiaohongshu import (
    XiaohongshuScraper,
    get_supabase_client,
    DEFAULT_KEYWORDS,
)
from app.services.xiaohongshu.scraper import load_cookies

from .schemas import (
    KeywordScrapeRequest,
    SingleKeywordRequest,
    ScrapeResponse,
)
from .task_manager import (
    generate_task_id,
    create_task,
    get_task,
    list_tasks,
)
from .background_tasks import (
    run_xhs_scrape_task,
    run_xhs_default_keywords_task,
    run_xhs_single_keyword_task,
)

router = APIRouter()


def _check_login_status():
    """æ£€æŸ¥ç™»å½•çŠ¶æ€ï¼Œæœªç™»å½•åˆ™æŠ›å‡ºå¼‚å¸¸"""
    cookies = load_cookies()
    if not cookies or len(cookies) == 0:
        raise HTTPException(
            status_code=401,
            detail={
                "error": "æœªç™»å½•",
                "message": "è¯·å…ˆåœ¨æœåŠ¡å™¨ä¸Šæ‰§è¡Œç™»å½•å‘½ä»¤",
                "login_command": "python -m app.services.xiaohongshu --login",
            }
        )
    return cookies


# ============================================================
# çˆ¬å– API ç«¯ç‚¹
# ============================================================


@router.post("/scrape", response_model=ScrapeResponse)
def scrape_keywords(
    request: KeywordScrapeRequest,
    background_tasks: BackgroundTasks,
):
    """
    ğŸ“± æ‰¹é‡çˆ¬å–å°çº¢ä¹¦ç¾è‚¡å¸–å­

    è¯·æ±‚ç¤ºä¾‹:
    ```json
    {
        "keywords": ["ç¾è‚¡", "è‹±ä¼Ÿè¾¾", "ç‰¹æ–¯æ‹‰"],
        "max_posts": 20,
        "fetch_details": true
    }
    ```

    æ³¨æ„ï¼š
    - æ­¤ç«¯ç‚¹ä¼šåœ¨åå°æ‰§è¡Œçˆ¬å–ä»»åŠ¡ï¼Œç«‹å³è¿”å›ä»»åŠ¡ ID
    - éœ€è¦å…ˆç™»å½•ï¼špython -m app.services.xiaohongshu --login
    """
    # æ£€æŸ¥ç™»å½•çŠ¶æ€
    _check_login_status()

    # ç”Ÿæˆä»»åŠ¡ ID
    task_id = generate_task_id()

    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    create_task(
        task_id,
        keywords=request.keywords,
        total_keywords=len(request.keywords),
        fetch_details=request.fetch_details,
    )

    # åœ¨åå°æ‰§è¡Œçˆ¬å–
    background_tasks.add_task(
        run_xhs_scrape_task,
        task_id,
        request.keywords,
        request.max_posts,
        request.fetch_details,
    )

    return ScrapeResponse(
        success=True,
        message=f"ğŸš€ å°çº¢ä¹¦çˆ¬å–ä»»åŠ¡å·²å¯åŠ¨ï¼Œå…± {len(request.keywords)} ä¸ªå…³é”®è¯",
        task_id=task_id,
    )


@router.post("/scrape-default", response_model=ScrapeResponse)
def scrape_default_keywords(
    max_posts: int = 20,
    fetch_details: bool = True,
    background_tasks: BackgroundTasks = None,
):
    """
    ğŸ”„ çˆ¬å–é»˜è®¤ç¾è‚¡å…³é”®è¯

    ä½¿ç”¨é¢„è®¾çš„ç¾è‚¡ç›¸å…³å…³é”®è¯è¿›è¡Œçˆ¬å–:
    - ç¾è‚¡ã€ç¾è‚¡æŠ•èµ„ã€ç¾è‚¡åˆ†æ
    - NVDAã€è‹±ä¼Ÿè¾¾ã€ç‰¹æ–¯æ‹‰
    - è‹¹æœè‚¡ç¥¨ã€çº³æ–¯è¾¾å…‹ã€æ ‡æ™®500

    å‚æ•°ï¼š
    - max_posts: æ¯ä¸ªå…³é”®è¯æœ€å¤šçˆ¬å–çš„å¸–å­æ•°é‡ (é»˜è®¤: 20)
    - fetch_details: æ˜¯å¦è·å–è¯¦æƒ…é¡µ (é»˜è®¤: true)
    
    æ³¨æ„ï¼šéœ€è¦å…ˆç™»å½•ï¼špython -m app.services.xiaohongshu --login
    """
    # æ£€æŸ¥ç™»å½•çŠ¶æ€
    _check_login_status()
    
    # ç”Ÿæˆä»»åŠ¡ ID
    task_id = generate_task_id()

    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    create_task(
        task_id,
        keywords=DEFAULT_KEYWORDS,
        total_keywords=len(DEFAULT_KEYWORDS),
        fetch_details=fetch_details,
    )

    # åœ¨åå°æ‰§è¡Œçˆ¬å–
    background_tasks.add_task(
        run_xhs_default_keywords_task,
        task_id,
        max_posts,
        fetch_details,
    )

    return ScrapeResponse(
        success=True,
        message=f"ğŸš€ å¼€å§‹çˆ¬å– {len(DEFAULT_KEYWORDS)} ä¸ªé»˜è®¤ç¾è‚¡å…³é”®è¯",
        task_id=task_id,
    )


@router.post("/scrape-single", response_model=Dict)
def scrape_single_keyword_sync(
    request: SingleKeywordRequest,
):
    """
    ğŸ” åŒæ­¥çˆ¬å–å•ä¸ªå…³é”®è¯ï¼ˆé˜»å¡å¼ï¼Œç­‰å¾…å®Œæˆï¼‰

    é€‚ç”¨äºæµ‹è¯•æˆ–éœ€è¦ç«‹å³è·å–ç»“æœçš„åœºæ™¯

    æ³¨æ„ï¼š
    - æ­¤ç«¯ç‚¹ä¼šé˜»å¡ç›´åˆ°çˆ¬å–å®Œæˆï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
    - éœ€è¦å…ˆç™»å½•ï¼špython -m app.services.xiaohongshu --login
    """
    # æ£€æŸ¥ç™»å½•çŠ¶æ€
    _check_login_status()
    
    try:
        scraper = XiaohongshuScraper(
            headless=True,
            max_posts=request.max_posts,
            fetch_details=request.fetch_details,
        )

        # è¿™é‡Œä½¿ç”¨åŒæ­¥æ–¹å¼æ‰§è¡Œ
        stats = scraper.scrape(keywords=[request.keyword])

        return {
            "success": True,
            "keyword": request.keyword,
            "stats": stats,
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"çˆ¬å–å¤±è´¥: {str(e)}")


@router.post("/scrape-single/{keyword}", response_model=ScrapeResponse)
def scrape_single_keyword_async(
    keyword: str,
    max_posts: int = 20,
    fetch_details: bool = True,
    background_tasks: BackgroundTasks = None,
):
    """
    ğŸ” å¼‚æ­¥çˆ¬å–å•ä¸ªå…³é”®è¯

    å‚æ•°ï¼š
    - keyword: æœç´¢å…³é”®è¯ï¼ˆURL è·¯å¾„å‚æ•°ï¼‰
    - max_posts: æœ€å¤šçˆ¬å–çš„å¸–å­æ•°é‡ (é»˜è®¤: 20)
    - fetch_details: æ˜¯å¦è·å–è¯¦æƒ…é¡µ (é»˜è®¤: true)
    
    æ³¨æ„ï¼šéœ€è¦å…ˆç™»å½•ï¼špython -m app.services.xiaohongshu --login
    """
    # æ£€æŸ¥ç™»å½•çŠ¶æ€
    _check_login_status()
    
    # ç”Ÿæˆä»»åŠ¡ ID
    task_id = generate_task_id()

    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    create_task(
        task_id,
        keywords=[keyword],
        total_keywords=1,
        fetch_details=fetch_details,
    )

    # åœ¨åå°æ‰§è¡Œçˆ¬å–
    background_tasks.add_task(
        run_xhs_single_keyword_task,
        task_id,
        keyword,
        max_posts,
        fetch_details,
    )

    return ScrapeResponse(
        success=True,
        message=f"ğŸ” å¼€å§‹çˆ¬å–å…³é”®è¯: {keyword}",
        task_id=task_id,
    )


# ============================================================
# ä»»åŠ¡æŸ¥è¯¢ç«¯ç‚¹
# ============================================================


@router.get("/task/{task_id}", response_model=Dict)
def get_task_status(task_id: str):
    """
    ğŸ“‹ è·å–çˆ¬å–ä»»åŠ¡çŠ¶æ€

    è¿”å›ä»»åŠ¡çš„å½“å‰çŠ¶æ€ã€ç»Ÿè®¡ä¿¡æ¯å’Œé”™è¯¯ï¼ˆå¦‚æœæœ‰ï¼‰
    """
    task = get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

    return task


@router.get("/tasks", response_model=List[Dict])
def list_recent_tasks(limit: int = 10):
    """
    ğŸ“‹ åˆ—å‡ºæœ€è¿‘çš„çˆ¬å–ä»»åŠ¡
    """
    return list_tasks(limit)

