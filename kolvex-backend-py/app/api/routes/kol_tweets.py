"""
KOL Tweets API è·¯ç”±
æä¾› KOL æ¨æ–‡æ•°æ®çš„ RESTful API
"""

from fastapi import APIRouter, Query, HTTPException
from typing import Optional, List
from pydantic import BaseModel
from datetime import datetime
from app.core.supabase import get_supabase_service

router = APIRouter(prefix="/kol-tweets", tags=["KOL Tweets"])


# ============================================================
# Pydantic æ¨¡å‹
# ============================================================


class MediaItem(BaseModel):
    """åª’ä½“é¡¹æ¨¡å‹"""

    type: str  # "photo", "video", "gif", "card"
    url: Optional[str] = None
    poster: Optional[str] = None


class SentimentAnalysis(BaseModel):
    """æƒ…æ„Ÿåˆ†æç»“æœ"""

    value: Optional[str] = None  # "bullish", "bearish", "neutral"
    confidence: Optional[float] = None  # 0.0 - 1.0
    reasoning: Optional[str] = None


class TradingSignal(BaseModel):
    """æŠ•èµ„ä¿¡å·"""

    action: Optional[str] = None  # "buy", "sell", "hold"
    tickers: List[str] = []
    confidence: Optional[float] = None  # 0.0 - 1.0


class KOLTweet(BaseModel):
    """KOL æ¨æ–‡æ¨¡å‹"""

    id: int
    username: str
    display_name: Optional[str] = None
    kol_description: Optional[str] = None
    avatar_url: Optional[str] = None
    tweet_text: str
    created_at: Optional[datetime] = None
    permalink: Optional[str] = None
    # åª’ä½“
    media_urls: Optional[List[MediaItem]] = None
    # è½¬å‘ä¿¡æ¯
    is_repost: bool = False
    original_author: Optional[str] = None
    # äº’åŠ¨æ•°æ®
    like_count: int = 0
    retweet_count: int = 0
    reply_count: int = 0
    bookmark_count: int = 0
    views_count: int = 0
    # å…ƒæ•°æ®
    scraped_at: Optional[datetime] = None
    category: Optional[str] = None

    # ========== AI åˆ†æå­—æ®µ ==========
    # æƒ…æ„Ÿåˆ†æ
    sentiment: Optional[SentimentAnalysis] = None
    # è‚¡ç¥¨ä»£ç 
    tickers: List[str] = []
    # AI æ ‡ç­¾
    tags: List[str] = []
    # æŠ•èµ„ä¿¡å·
    trading_signal: Optional[TradingSignal] = None
    # æ‘˜è¦
    summary: Optional[str] = None
    summary_en: Optional[str] = None
    # AI åˆ†æå…ƒæ•°æ®
    ai_analyzed_at: Optional[datetime] = None
    ai_model: Optional[str] = None


class KOLTweetsResponse(BaseModel):
    """KOL æ¨æ–‡åˆ—è¡¨å“åº”"""

    tweets: List[KOLTweet]
    total: int
    page: int
    page_size: int
    has_more: bool


class KOLProfile(BaseModel):
    """KOL å®Œæ•´ Profile æ¨¡å‹ - åŒ¹é… kol_profiles è¡¨"""

    id: int
    username: str
    display_name: Optional[str] = None
    description: Optional[str] = None
    category: Optional[str] = None
    followers_count: int = 0
    following_count: int = 0
    posts_count: int = 0
    avatar_url: Optional[str] = None
    banner_url: Optional[str] = None
    is_active: bool = True
    is_verified: bool = False
    verification_type: Optional[str] = "None"
    rest_id: Optional[str] = None
    join_date: Optional[str] = None
    location: Optional[str] = None
    website: Optional[str] = None
    bio: Optional[str] = None
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None


class KOLProfilesResponse(BaseModel):
    """KOL åˆ—è¡¨å“åº”"""

    profiles: List[KOLProfile]
    total: int


class KOLProfileDetail(BaseModel):
    """KOL è¯¦ç»†ä¿¡æ¯ï¼ˆå«ç»Ÿè®¡ï¼‰"""

    profile: KOLProfile
    tweet_count: int = 0
    total_likes: int = 0
    total_retweets: int = 0
    recent_tweets: List[KOLTweet] = []


class CategoryStats(BaseModel):
    """ç±»åˆ«ç»Ÿè®¡æ¨¡å‹"""

    category: str
    kol_count: int
    tweet_count: int
    total_likes: int
    last_scraped_at: Optional[datetime] = None


class StatsResponse(BaseModel):
    """ç»Ÿè®¡å“åº”"""

    total_tweets: int
    total_kols: int
    categories: List[CategoryStats]


# ============================================================
# API è·¯ç”±
# ============================================================


@router.get("/", response_model=KOLTweetsResponse)
async def get_kol_tweets(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    category: Optional[str] = Query(None, description="ç±»åˆ«ç­›é€‰"),
    username: Optional[str] = Query(None, description="ç”¨æˆ·åç­›é€‰"),
    search: Optional[str] = Query(None, description="æœç´¢å…³é”®è¯"),
):
    """
    è·å– KOL æ¨æ–‡åˆ—è¡¨

    - **page**: é¡µç ï¼Œä» 1 å¼€å§‹
    - **page_size**: æ¯é¡µæ•°é‡ï¼Œé»˜è®¤ 20ï¼Œæœ€å¤§ 100
    - **category**: å¯é€‰ï¼ŒæŒ‰ç±»åˆ«ç­›é€‰ (news_flow, short_macro, charts_data, institutional, retail_meme)
    - **username**: å¯é€‰ï¼ŒæŒ‰ç”¨æˆ·åç­›é€‰
    - **search**: å¯é€‰ï¼Œæœç´¢æ¨æ–‡å†…å®¹
    """
    try:
        supabase = get_supabase_service()
        offset = (page - 1) * page_size

        # æŸ¥è¯¢ kol_tweets è¡¨ï¼ˆä¸ä½¿ç”¨å…³ç³»æŸ¥è¯¢ï¼Œé¿å…å¤–é”®ä¾èµ–ï¼‰
        query = supabase.table("kol_tweets").select(
            "id, username, tweet_text, created_at, permalink, "
            "avatar_url, media_urls, is_repost, original_author, "
            "like_count, retweet_count, reply_count, bookmark_count, views_count, "
            "scraped_at, category, "
            # AI åˆ†æå­—æ®µ
            "ai_sentiment, ai_sentiment_confidence, ai_sentiment_reasoning, "
            "ai_tickers, ai_tags, ai_trading_signal, "
            "ai_summary, ai_summary_en, ai_analyzed_at, ai_model",
            count="exact",
        )

        # åº”ç”¨ç­›é€‰æ¡ä»¶
        if category:
            query = query.eq("category", category)
        if username:
            query = query.eq("username", username)
        if search:
            query = query.ilike("tweet_text", f"%{search}%")

        # æŒ‰æ¨æ–‡åˆ›å»ºæ—¶é—´æ’åºï¼ˆä¼˜å…ˆï¼‰ï¼Œscraped_at ä½œä¸ºå¤‡ç”¨
        result = (
            query.order("created_at", desc=True, nullsfirst=False)
            .range(offset, offset + page_size - 1)
            .execute()
        )

        # è·å–æ‰€æœ‰ç”¨æˆ·åä»¥æŸ¥è¯¢ profile ä¿¡æ¯
        usernames = list(set(row["username"] for row in result.data))

        # å•ç‹¬æŸ¥è¯¢ kol_profiles è¡¨è·å–ç”¨æˆ·ä¿¡æ¯
        profiles_map = {}
        if usernames:
            try:
                profiles_result = (
                    supabase.table("kol_profiles")
                    .select("username, display_name, description, avatar_url")
                    .in_("username", usernames)
                    .execute()
                )
                profiles_map = {p["username"]: p for p in profiles_result.data}
            except Exception:
                # kol_profiles è¡¨å¯èƒ½ä¸å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
                pass

        # è½¬æ¢æ•°æ®æ ¼å¼
        tweets = []
        for row in result.data:
            profile = profiles_map.get(row["username"], {})

            # è§£æ media_urls (å¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²æˆ–å·²è§£æçš„åˆ—è¡¨)
            media_urls_raw = row.get("media_urls")
            media_urls = None
            if media_urls_raw:
                if isinstance(media_urls_raw, str):
                    import json

                    try:
                        media_urls = json.loads(media_urls_raw)
                    except:
                        media_urls = None
                elif isinstance(media_urls_raw, list):
                    media_urls = media_urls_raw

            # ä¼˜å…ˆä½¿ç”¨æ¨æ–‡ä¸­çš„ avatar_urlï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ profile ä¸­çš„
            avatar_url = row.get("avatar_url") or profile.get("avatar_url")

            # è§£æ AI åˆ†æå­—æ®µ
            sentiment = None
            if row.get("ai_sentiment"):
                sentiment = SentimentAnalysis(
                    value=row.get("ai_sentiment"),
                    confidence=row.get("ai_sentiment_confidence"),
                    reasoning=row.get("ai_sentiment_reasoning"),
                )

            trading_signal = None
            if row.get("ai_trading_signal"):
                signal_data = row.get("ai_trading_signal")
                if isinstance(signal_data, str):
                    import json

                    try:
                        signal_data = json.loads(signal_data)
                    except:
                        signal_data = None
                if signal_data:
                    trading_signal = TradingSignal(**signal_data)

            # è§£æ tickers å’Œ tags (JSONB å­—æ®µ)
            ai_tickers = row.get("ai_tickers") or []
            ai_tags = row.get("ai_tags") or []
            if isinstance(ai_tickers, str):
                import json

                try:
                    ai_tickers = json.loads(ai_tickers)
                except:
                    ai_tickers = []
            if isinstance(ai_tags, str):
                import json

                try:
                    ai_tags = json.loads(ai_tags)
                except:
                    ai_tags = []

            tweets.append(
                KOLTweet(
                    id=row["id"],
                    username=row["username"],
                    display_name=profile.get("display_name"),
                    kol_description=profile.get("description"),
                    avatar_url=avatar_url,
                    tweet_text=row["tweet_text"],
                    created_at=row.get("created_at"),
                    permalink=row.get("permalink"),
                    media_urls=(
                        [MediaItem(**m) for m in media_urls] if media_urls else None
                    ),
                    is_repost=row.get("is_repost", False) or False,
                    original_author=row.get("original_author"),
                    like_count=row.get("like_count", 0) or 0,
                    retweet_count=row.get("retweet_count", 0) or 0,
                    reply_count=row.get("reply_count", 0) or 0,
                    bookmark_count=row.get("bookmark_count", 0) or 0,
                    views_count=row.get("views_count", 0) or 0,
                    scraped_at=row.get("scraped_at"),
                    category=row.get("category"),
                    # AI åˆ†æå­—æ®µ
                    sentiment=sentiment,
                    tickers=ai_tickers,
                    tags=ai_tags,
                    trading_signal=trading_signal,
                    summary=row.get("ai_summary"),
                    summary_en=row.get("ai_summary_en"),
                    ai_analyzed_at=row.get("ai_analyzed_at"),
                    ai_model=row.get("ai_model"),
                )
            )

        total = result.count or 0
        has_more = offset + len(tweets) < total

        return KOLTweetsResponse(
            tweets=tweets,
            total=total,
            page=page,
            page_size=page_size,
            has_more=has_more,
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ¨æ–‡å¤±è´¥: {str(e)}")


@router.get("/profiles", response_model=KOLProfilesResponse)
async def get_kol_profiles(
    category: Optional[str] = Query(None, description="ç±»åˆ«ç­›é€‰"),
    sort_by: str = Query("followers_count", description="æ’åºå­—æ®µ"),
    sort_order: str = Query("desc", description="æ’åºé¡ºåº asc/desc"),
):
    """
    è·å– KOL åˆ—è¡¨ï¼ˆå®Œæ•´ profile æ•°æ®ï¼‰

    - **category**: å¯é€‰ï¼ŒæŒ‰ç±»åˆ«ç­›é€‰
    - **sort_by**: æ’åºå­—æ®µ (followers_count, posts_count, updated_at)
    - **sort_order**: asc æˆ– desc
    """
    try:
        supabase = get_supabase_service()

        # ç›´æ¥æŸ¥è¯¢ kol_profiles è¡¨è·å–æ‰€æœ‰å­—æ®µ
        query = supabase.table("kol_profiles").select(
            "id, username, display_name, description, category, "
            "followers_count, following_count, posts_count, "
            "avatar_url, banner_url, is_active, is_verified, verification_type, "
            "rest_id, join_date, location, website, bio, created_at, updated_at",
            count="exact",
        )

        # ç­›é€‰æ¡ä»¶
        if category:
            query = query.eq("category", category)

        # æ’åº
        is_desc = sort_order.lower() == "desc"
        if sort_by in [
            "followers_count",
            "posts_count",
            "following_count",
            "updated_at",
            "created_at",
        ]:
            query = query.order(sort_by, desc=is_desc)
        else:
            query = query.order("followers_count", desc=True)

        result = query.execute()

        profiles = [
            KOLProfile(
                id=row["id"],
                username=row["username"],
                display_name=row.get("display_name"),
                description=row.get("description"),
                category=row.get("category"),
                followers_count=row.get("followers_count", 0) or 0,
                following_count=row.get("following_count", 0) or 0,
                posts_count=row.get("posts_count", 0) or 0,
                avatar_url=row.get("avatar_url"),
                banner_url=row.get("banner_url"),
                is_active=row.get("is_active", True),
                is_verified=row.get("is_verified", False),
                verification_type=row.get("verification_type", "None"),
                rest_id=row.get("rest_id"),
                join_date=row.get("join_date"),
                location=row.get("location"),
                website=row.get("website"),
                bio=row.get("bio"),
                created_at=row.get("created_at"),
                updated_at=row.get("updated_at"),
            )
            for row in result.data
        ]

        return KOLProfilesResponse(
            profiles=profiles, total=result.count or len(profiles)
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å– KOL åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/stats", response_model=StatsResponse)
async def get_stats():
    """
    è·å–ç»Ÿè®¡ä¿¡æ¯
    """
    try:
        supabase = get_supabase_service()

        # æ€»æ¨æ–‡æ•°
        tweets_result = (
            supabase.table("kol_tweets").select("id", count="exact").execute()
        )
        total_tweets = tweets_result.count or 0

        # æ€» KOL æ•°
        try:
            kols_result = (
                supabase.table("kol_profiles").select("id", count="exact").execute()
            )
            total_kols = kols_result.count or 0
        except Exception:
            # è¡¨å¯èƒ½ä¸å­˜åœ¨
            total_kols = 0

        # å°è¯•ä½¿ç”¨ç±»åˆ«ç»Ÿè®¡è§†å›¾
        categories = []
        try:
            cat_result = supabase.table("v_category_stats").select("*").execute()
            categories = [
                CategoryStats(
                    category=row["category"],
                    kol_count=row.get("kol_count", 0),
                    tweet_count=row.get("tweet_count", 0),
                    total_likes=row.get("total_likes", 0),
                    last_scraped_at=row.get("last_scraped_at"),
                )
                for row in cat_result.data
            ]
        except Exception:
            # è§†å›¾ä¸å­˜åœ¨ï¼Œæ‰‹åŠ¨èšåˆ
            pass

        return StatsResponse(
            total_tweets=total_tweets,
            total_kols=total_kols,
            categories=categories,
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")


@router.get("/categories")
async def get_categories():
    """
    è·å–æ‰€æœ‰ç±»åˆ«
    """
    return {
        "categories": [
            {
                "id": "news_flow",
                "name": "News & Flow",
                "icon": "ğŸš¨",
                "description": "é€Ÿåº¦æœ€å¿«çš„æ•°æ®æº",
            },
            {
                "id": "short_macro",
                "name": "Short & Macro",
                "icon": "ğŸ“‰",
                "description": "å®è§‚ä¸ç©ºå¤´",
            },
            {
                "id": "charts_data",
                "name": "Charts & Data",
                "icon": "ğŸ“Š",
                "description": "ç¡¬æ ¸æ•°æ®æ´¾",
            },
            {
                "id": "institutional",
                "name": "Institutional",
                "icon": "ğŸ‚",
                "description": "ä¸»æµå£°éŸ³",
            },
            {
                "id": "retail_meme",
                "name": "Retail & Meme",
                "icon": "ğŸ¦",
                "description": "æ•£æˆ·é£å‘æ ‡",
            },
        ]
    }


@router.get("/user/{username}", response_model=KOLTweetsResponse)
async def get_user_tweets(
    username: str,
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
):
    """
    è·å–ç‰¹å®šç”¨æˆ·çš„æ¨æ–‡
    """
    return await get_kol_tweets(page=page, page_size=page_size, username=username)


@router.get("/profile/{username}", response_model=KOLProfileDetail)
async def get_kol_profile_detail(
    username: str,
    include_tweets: bool = Query(True, description="æ˜¯å¦åŒ…å«æœ€è¿‘æ¨æ–‡"),
    tweet_limit: int = Query(10, ge=1, le=50, description="æœ€è¿‘æ¨æ–‡æ•°é‡"),
):
    """
    è·å–ç‰¹å®š KOL çš„å®Œæ•´ Profile ä¿¡æ¯

    - **username**: KOL ç”¨æˆ·å
    - **include_tweets**: æ˜¯å¦åŒ…å«æœ€è¿‘æ¨æ–‡
    - **tweet_limit**: è¿”å›çš„æœ€è¿‘æ¨æ–‡æ•°é‡
    """
    try:
        supabase = get_supabase_service()

        # æŸ¥è¯¢ profile
        profile_result = (
            supabase.table("kol_profiles")
            .select(
                "id, username, display_name, description, category, "
                "followers_count, following_count, posts_count, "
                "avatar_url, banner_url, is_active, is_verified, verification_type, "
                "rest_id, join_date, location, website, bio, created_at, updated_at"
            )
            .eq("username", username)
            .execute()
        )

        if not profile_result.data:
            raise HTTPException(status_code=404, detail=f"KOL '{username}' ä¸å­˜åœ¨")

        row = profile_result.data[0]
        profile = KOLProfile(
            id=row["id"],
            username=row["username"],
            display_name=row.get("display_name"),
            description=row.get("description"),
            category=row.get("category"),
            followers_count=row.get("followers_count", 0) or 0,
            following_count=row.get("following_count", 0) or 0,
            posts_count=row.get("posts_count", 0) or 0,
            avatar_url=row.get("avatar_url"),
            banner_url=row.get("banner_url"),
            is_active=row.get("is_active", True),
            is_verified=row.get("is_verified", False),
            verification_type=row.get("verification_type", "None"),
            rest_id=row.get("rest_id"),
            join_date=row.get("join_date"),
            location=row.get("location"),
            website=row.get("website"),
            bio=row.get("bio"),
            created_at=row.get("created_at"),
            updated_at=row.get("updated_at"),
        )

        # ç»Ÿè®¡è¯¥ KOL çš„æ¨æ–‡æ•°æ®ï¼ˆå§‹ç»ˆæŸ¥è¯¢ï¼‰
        stats_result = (
            supabase.table("kol_tweets")
            .select("id, like_count, retweet_count")
            .eq("username", username)
            .execute()
        )

        tweet_count = len(stats_result.data)
        total_likes = sum(t.get("like_count", 0) or 0 for t in stats_result.data)
        total_retweets = sum(t.get("retweet_count", 0) or 0 for t in stats_result.data)

        # è·å–æœ€è¿‘æ¨æ–‡ï¼ˆä»…å½“ include_tweets=True æ—¶ï¼‰
        recent_tweets = []
        if include_tweets:
            tweets_result = (
                supabase.table("kol_tweets")
                .select(
                    "id, username, tweet_text, created_at, permalink, "
                    "avatar_url, media_urls, is_repost, original_author, "
                    "like_count, retweet_count, reply_count, bookmark_count, views_count, "
                    "scraped_at, category, "
                    "ai_sentiment, ai_sentiment_confidence, ai_sentiment_reasoning, "
                    "ai_tickers, ai_tags, ai_trading_signal, "
                    "ai_summary, ai_summary_en, ai_analyzed_at, ai_model"
                )
                .eq("username", username)
                .order("created_at", desc=True, nullsfirst=False)
                .limit(tweet_limit)
                .execute()
            )

            for t in tweets_result.data:
                # è§£æ media_urls
                media_urls_raw = t.get("media_urls")
                media_urls = None
                if media_urls_raw:
                    if isinstance(media_urls_raw, str):
                        import json

                        try:
                            media_urls = json.loads(media_urls_raw)
                        except:
                            media_urls = None
                    elif isinstance(media_urls_raw, list):
                        media_urls = media_urls_raw

                # è§£æ AI åˆ†æå­—æ®µ
                sentiment = None
                if t.get("ai_sentiment"):
                    sentiment = SentimentAnalysis(
                        value=t.get("ai_sentiment"),
                        confidence=t.get("ai_sentiment_confidence"),
                        reasoning=t.get("ai_sentiment_reasoning"),
                    )

                trading_signal = None
                if t.get("ai_trading_signal"):
                    signal_data = t.get("ai_trading_signal")
                    if isinstance(signal_data, str):
                        import json

                        try:
                            signal_data = json.loads(signal_data)
                        except:
                            signal_data = None
                    if signal_data:
                        trading_signal = TradingSignal(**signal_data)

                ai_tickers = t.get("ai_tickers") or []
                ai_tags = t.get("ai_tags") or []
                if isinstance(ai_tickers, str):
                    import json

                    try:
                        ai_tickers = json.loads(ai_tickers)
                    except:
                        ai_tickers = []
                if isinstance(ai_tags, str):
                    import json

                    try:
                        ai_tags = json.loads(ai_tags)
                    except:
                        ai_tags = []

                recent_tweets.append(
                    KOLTweet(
                        id=t["id"],
                        username=t["username"],
                        display_name=profile.display_name,
                        kol_description=profile.description,
                        avatar_url=t.get("avatar_url") or profile.avatar_url,
                        tweet_text=t["tweet_text"],
                        created_at=t.get("created_at"),
                        permalink=t.get("permalink"),
                        media_urls=(
                            [MediaItem(**m) for m in media_urls] if media_urls else None
                        ),
                        is_repost=t.get("is_repost", False) or False,
                        original_author=t.get("original_author"),
                        like_count=t.get("like_count", 0) or 0,
                        retweet_count=t.get("retweet_count", 0) or 0,
                        reply_count=t.get("reply_count", 0) or 0,
                        bookmark_count=t.get("bookmark_count", 0) or 0,
                        views_count=t.get("views_count", 0) or 0,
                        scraped_at=t.get("scraped_at"),
                        category=t.get("category"),
                        # AI åˆ†æå­—æ®µ
                        sentiment=sentiment,
                        tickers=ai_tickers,
                        tags=ai_tags,
                        trading_signal=trading_signal,
                        summary=t.get("ai_summary"),
                        summary_en=t.get("ai_summary_en"),
                        ai_analyzed_at=t.get("ai_analyzed_at"),
                        ai_model=t.get("ai_model"),
                    )
                )

        return KOLProfileDetail(
            profile=profile,
            tweet_count=tweet_count,
            total_likes=total_likes,
            total_retweets=total_retweets,
            recent_tweets=recent_tweets,
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å– KOL ä¿¡æ¯å¤±è´¥: {str(e)}")
