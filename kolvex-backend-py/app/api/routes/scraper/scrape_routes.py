"""
çˆ¬å– API è·¯ç”±
æä¾› KOL æ¨æ–‡çˆ¬å–ç›¸å…³çš„ REST API ç«¯ç‚¹
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from typing import List, Dict, Optional

from app.services.scraper import (
    BatchKOLScraper,
    get_supabase_client,
    load_cookies,
)

from .schemas import (
    BatchScrapeRequest,
    ScrapeResponse,
)
from .task_manager import (
    generate_task_id,
    create_task,
    get_task,
    list_tasks,
)
from .background_tasks import (
    run_scrape_task,
    run_all_profiles_scrape_task,
)

router = APIRouter()


# ============================================================
# çˆ¬å– API ç«¯ç‚¹
# ============================================================


@router.post("/scrape", response_model=ScrapeResponse)
def scrape_kols(
    request: BatchScrapeRequest,
    background_tasks: BackgroundTasks,
):
    """
    æ‰¹é‡çˆ¬å– KOL æ¨æ–‡

    è¯·æ±‚ç¤ºä¾‹:
    ```json
    {
        "usernames": ["elonmusk", "unusual_whales", "zerohedge"],
        "max_posts_per_user": 10
    }
    ```

    æ³¨æ„ï¼šæ­¤ç«¯ç‚¹ä¼šåœ¨åå°æ‰§è¡Œçˆ¬å–ä»»åŠ¡ï¼Œç«‹å³è¿”å›ä»»åŠ¡ ID
    """
    # æ£€æŸ¥ cookies
    cookies = load_cookies()
    if not cookies:
        raise HTTPException(
            status_code=400, detail="æœªæ‰¾åˆ° cookies æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ setup æ¨¡å¼ç™»å½•"
        )

    # ç”Ÿæˆä»»åŠ¡ ID
    task_id = generate_task_id()

    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    create_task(task_id, usernames=request.usernames)

    # åœ¨åå°æ‰§è¡Œçˆ¬å–
    background_tasks.add_task(
        run_scrape_task,
        task_id,
        request.usernames,
        request.max_posts_per_user,
    )

    return ScrapeResponse(
        success=True,
        message=f"çˆ¬å–ä»»åŠ¡å·²å¯åŠ¨ï¼Œå…± {len(request.usernames)} ä¸ªç”¨æˆ·",
        task_id=task_id,
    )


@router.post("/scrape-all-profiles", response_model=ScrapeResponse)
def scrape_all_kol_profiles(
    max_posts_per_user: int = 10,
    background_tasks: BackgroundTasks = None,
):
    """
    ğŸ”„ çˆ¬å–æ•°æ®åº“ä¸­æ‰€æœ‰ KOL çš„æœ€æ–°æ¨æ–‡

    ä» Supabase çš„ kol_profiles è¡¨è·å–æ‰€æœ‰ KOLï¼Œ
    ç„¶åçˆ¬å–æ¯ä¸ª KOL çš„æœ€æ–°æ¨æ–‡ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰ã€‚

    - å·²å­˜åœ¨çš„æ¨æ–‡ä¼šè‡ªåŠ¨è·³è¿‡
    - æ–°æ¨æ–‡ä¼šæ·»åŠ åˆ° kol_tweets è¡¨

    å‚æ•°ï¼š
    - max_posts_per_user: æ¯ä¸ªç”¨æˆ·æœ€å¤šçˆ¬å–çš„æ¨æ–‡æ•°é‡ (é»˜è®¤: 10)
    """
    # æ£€æŸ¥ cookies
    cookies = load_cookies()
    if not cookies:
        raise HTTPException(
            status_code=400, detail="æœªæ‰¾åˆ° cookies æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ setup æ¨¡å¼ç™»å½•"
        )

    # è·å– Supabase å®¢æˆ·ç«¯
    supabase = get_supabase_client()
    if not supabase:
        raise HTTPException(status_code=503, detail="Supabase æœªè¿æ¥")

    # ä» kol_profiles è¡¨è·å–æ‰€æœ‰ KOL
    try:
        profiles_result = (
            supabase.table("kol_profiles")
            .select("username")
            .eq("is_active", True)
            .execute()
        )
        kol_profiles = profiles_result.data or []
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å– KOL åˆ—è¡¨å¤±è´¥: {str(e)}")

    if not kol_profiles:
        raise HTTPException(status_code=404, detail="kol_profiles è¡¨ä¸­æ²¡æœ‰æ´»è·ƒçš„ KOL")

    # ç”Ÿæˆä»»åŠ¡ ID
    task_id = generate_task_id()

    # æå–ç”¨æˆ·ååˆ—è¡¨
    usernames = [profile["username"] for profile in kol_profiles]

    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    create_task(
        task_id,
        usernames=usernames,
        source="kol_profiles",
        total_kols=len(usernames),
    )

    # åœ¨åå°æ‰§è¡Œçˆ¬å–
    background_tasks.add_task(
        run_all_profiles_scrape_task,
        task_id,
        usernames,
        max_posts_per_user,
    )

    return ScrapeResponse(
        success=True,
        message=f"ğŸš€ å¼€å§‹çˆ¬å– kol_profiles è¡¨ä¸­çš„ {len(usernames)} ä¸ª KOL çš„æœ€æ–°æ¨æ–‡",
        task_id=task_id,
    )


@router.post("/scrape-single/{username}", response_model=Dict)
def scrape_single_user(
    username: str,
    max_posts: int = 10,
):
    """
    åŒæ­¥çˆ¬å–å•ä¸ªç”¨æˆ·ï¼ˆé˜»å¡å¼ï¼Œç­‰å¾…å®Œæˆï¼‰

    é€‚ç”¨äºæµ‹è¯•æˆ–éœ€è¦ç«‹å³è·å–ç»“æœçš„åœºæ™¯

    æ³¨æ„ï¼šæ­¤ç«¯ç‚¹ä¼šé˜»å¡ç›´åˆ°çˆ¬å–å®Œæˆï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
    """
    # æ£€æŸ¥ cookies
    cookies = load_cookies()
    if not cookies:
        raise HTTPException(
            status_code=400, detail="æœªæ‰¾åˆ° cookies æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ setup æ¨¡å¼ç™»å½•"
        )

    try:
        scraper = BatchKOLScraper(
            headless=True,
            max_posts_per_user=max_posts,
        )

        # è¿™é‡Œä½¿ç”¨åŒæ­¥æ–¹å¼æ‰§è¡Œ
        stats = scraper.batch_scrape(usernames=[username])

        return {
            "success": True,
            "username": username,
            "stats": stats,
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"çˆ¬å–å¤±è´¥: {str(e)}")


# ============================================================
# ä»»åŠ¡æŸ¥è¯¢ç«¯ç‚¹
# ============================================================


@router.get("/task/{task_id}", response_model=Dict)
def get_task_status(task_id: str):
    """
    è·å–çˆ¬å–ä»»åŠ¡çŠ¶æ€

    è¿”å›ä»»åŠ¡çš„å½“å‰çŠ¶æ€ã€ç»Ÿè®¡ä¿¡æ¯å’Œé”™è¯¯ï¼ˆå¦‚æœæœ‰ï¼‰
    """
    task = get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

    return task


@router.get("/tasks", response_model=List[Dict])
def list_recent_tasks(limit: int = 10):
    """
    åˆ—å‡ºæœ€è¿‘çš„çˆ¬å–ä»»åŠ¡
    """
    return list_tasks(limit)
